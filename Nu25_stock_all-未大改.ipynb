{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 獲取歷史資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finlab.data import Data\n",
    "\n",
    "data = Data()\n",
    "\n",
    "rev = data.get(\"當月營收\")\n",
    "close = data.get(\"收盤價\")\n",
    "open_ = data.get(\"開盤價\")\n",
    "high = data.get(\"最高價\")\n",
    "low = data.get(\"最低價\")\n",
    "vol = data.get(\"成交股數\")\n",
    "\n",
    "#財務指標\n",
    "PB = data.get(\"股價淨值比\")\n",
    "pe = data.get(\"本益比\")\n",
    "\n",
    "rev.index = rev.index.shift(5, \"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(n):\n",
    "    return close / close.rolling(n, min_periods=1).mean()\n",
    "\n",
    "def acc(n):\n",
    "    return close.shift(n) / (close.shift(2*n) + close) * 2\n",
    "\n",
    "def rsv(n):\n",
    "    l = close.rolling(n, min_periods=1).min()\n",
    "    h = close.rolling(n, min_periods=1).max()\n",
    "    \n",
    "    return (close - l) / (h - l)\n",
    "\n",
    "def mom(n):\n",
    "    return (rev / rev.shift(1)).shift(n)\n",
    "\n",
    "def yoy(n):\n",
    "    return (rev / rev.shift(12)).shift(n)\n",
    "\n",
    "\n",
    "\n",
    "features = {\n",
    "    \n",
    "    'PB':PB,\n",
    "    'PE':pe,    \n",
    "    \n",
    "    'mom1': mom(1),\n",
    "    'mom2': mom(2),\n",
    "    'mom3': mom(3),\n",
    "    'mom4': mom(4),\n",
    "    'mom5': mom(5),\n",
    "    'mom6': mom(6),\n",
    "    'mom7': mom(7),\n",
    "    'mom8': mom(8),\n",
    "    'mom9': mom(9),\n",
    "    \n",
    "    'yoy': yoy(1),\n",
    "    'delta_yoy':yoy(1)-yoy(2),\n",
    "    \n",
    "    'bias5': bias(5),\n",
    "    'bias10': bias(10),\n",
    "    'bias20': bias(20),\n",
    "    'bias60': bias(60),\n",
    "    'bias120': bias(120),\n",
    "    'bias240': bias(240),\n",
    "    \n",
    "    'acc5': acc(5),\n",
    "    'acc10': acc(10),\n",
    "    'acc20': acc(20),\n",
    "    'acc60': acc(60),\n",
    "    'acc120': acc(120),\n",
    "    'acc240': acc(240),\n",
    "    \n",
    "    'rsv5': rsv(5),\n",
    "    'rsv10': rsv(10),\n",
    "    'rsv20': rsv(20),\n",
    "    'rsv60': rsv(60),\n",
    "    'rsv120': rsv(120),\n",
    "    'rsv240': rsv(240),\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PB',\n",
       " 'PE',\n",
       " 'acc10',\n",
       " 'acc120',\n",
       " 'acc20',\n",
       " 'acc240',\n",
       " 'acc5',\n",
       " 'acc60',\n",
       " 'bias10',\n",
       " 'bias120',\n",
       " 'bias20',\n",
       " 'bias240',\n",
       " 'bias5',\n",
       " 'bias60',\n",
       " 'delta_yoy',\n",
       " 'mom1',\n",
       " 'mom2',\n",
       " 'mom3',\n",
       " 'mom4',\n",
       " 'mom5',\n",
       " 'mom6',\n",
       " 'mom7',\n",
       " 'mom8',\n",
       " 'mom9',\n",
       " 'rsv10',\n",
       " 'rsv120',\n",
       " 'rsv20',\n",
       " 'rsv240',\n",
       " 'rsv5',\n",
       " 'rsv60',\n",
       " 'yoy']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1=sorted(features)\n",
    "list1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 製作dataset\n",
    "\n",
    "##### 設定買賣頻率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2005-02-15', '2005-03-15', '2005-04-15', '2005-05-15',\n",
       "               '2005-06-15', '2005-07-15', '2005-08-15', '2005-09-15',\n",
       "               '2005-10-15', '2005-11-15',\n",
       "               ...\n",
       "               '2022-01-15', '2022-02-15', '2022-03-15', '2022-04-15',\n",
       "               '2022-05-15', '2022-06-15', '2022-07-15', '2022-08-15',\n",
       "               '2022-09-15', '2022-10-15'],\n",
       "              dtype='datetime64[ns]', name='date', length=213, freq=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "every_month = rev.index\n",
    "every_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 將dataframe 組裝起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features['bias20'].reindex(every_month, method='ffill')\n",
    "\n",
    "for name, f in features.items():\n",
    "    features[name] = f.reindex(every_month, method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, f in features.items():\n",
    "    features[name] = f.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finlab import ml\n",
    "\n",
    "ml.add_profit_prediction(dataset)\n",
    "ml.add_rank_prediction(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 刪除太大太小的歷史資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(433881, 33)\n",
      "(375244, 33)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "\n",
    "def drop_extreme_case(dataset, feature_names, thresh=0.01):\n",
    "    \n",
    "    extreme_cases = pd.Series(False, index=dataset.index)\n",
    "    for f in feature_names:\n",
    "        tf = dataset[f]\n",
    "        extreme_cases = extreme_cases | (tf < tf.quantile(thresh)) | (tf > tf.quantile(1-thresh))\n",
    "    dataset = dataset[~extreme_cases]\n",
    "    return dataset\n",
    "\n",
    "dataset_drop_extreme_case = drop_extreme_case(dataset,list1, thresh=0.01)\n",
    "\n",
    "print(dataset_drop_extreme_case.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dropna = dataset_drop_extreme_case.dropna(how='any')\n",
    "dataset_dropna = dataset_dropna.reset_index().set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2005-02-15', '2005-03-15', '2005-04-15', '2005-05-15',\n",
       "               '2005-06-15', '2005-07-15', '2005-08-15', '2005-09-15',\n",
       "               '2005-10-15', '2005-11-15',\n",
       "               ...\n",
       "               '2021-09-15', '2021-11-15', '2021-12-15', '2022-02-15',\n",
       "               '2022-03-15', '2022-04-15', '2022-06-15', '2022-08-15',\n",
       "               '2022-09-15', '2022-10-15'],\n",
       "              dtype='datetime64[ns]', name='date', length=375244, freq=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_drop_extreme_case.index.get_level_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_dropna.loc[:'2021']\n",
    "dataset_test = dataset_dropna.loc['2022':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神經網路模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               3200      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 13,401\n",
      "Trainable params: 13,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "start fitting\n",
      "Epoch 1/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.270 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.269 - ETA: 0s - loss: 0.267 - ETA: 0s - loss: 0.265 - ETA: 0s - loss: 0.263 - 1s 56ms/step - loss: 0.2629 - val_loss: 0.1296\n",
      "Epoch 2/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.245 - ETA: 0s - loss: 0.241 - ETA: 0s - loss: 0.236 - ETA: 0s - loss: 0.232 - ETA: 0s - loss: 0.226 - ETA: 0s - loss: 0.220 - 0s 31ms/step - loss: 0.2193 - val_loss: 0.0792\n",
      "Epoch 3/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.177 - ETA: 0s - loss: 0.166 - ETA: 0s - loss: 0.159 - ETA: 0s - loss: 0.150 - ETA: 0s - loss: 0.143 - ETA: 0s - loss: 0.136 - 0s 39ms/step - loss: 0.1350 - val_loss: 0.0741\n",
      "Epoch 4/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.094 - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.083 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - 0s 30ms/step - loss: 0.0800 - val_loss: 0.0729\n",
      "Epoch 5/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0734 - val_loss: 0.0728\n",
      "Epoch 6/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 7/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 8/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 9/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 33ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 10/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 33ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 11/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 12/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 13/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 14/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 15/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 16/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 34ms/step - loss: 0.0733 - val_loss: 0.0727\n",
      "Epoch 17/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 18/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 19/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 1s 51ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 20/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 21/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 22/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 1s 49ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 23/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 36ms/step - loss: 0.0733 - val_loss: 0.0728\n",
      "Epoch 24/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 41ms/step - loss: 0.0733 - val_loss: 0.0727\n",
      "Epoch 25/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 41ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 26/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 27/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0732 - val_loss: 0.0728\n",
      "Epoch 28/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0732 - val_loss: 0.0726\n",
      "Epoch 29/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 30/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 37ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 31/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 32/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0732 - val_loss: 0.0726\n",
      "Epoch 33/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 34/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0732 - val_loss: 0.0728\n",
      "Epoch 35/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0732 - val_loss: 0.0726\n",
      "Epoch 36/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 37ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 37/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 38/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 37ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 39/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 40/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0731 - val_loss: 0.0727\n",
      "Epoch 41/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 42/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 43/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 33ms/step - loss: 0.0731 - val_loss: 0.0727\n",
      "Epoch 44/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 45/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 46/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 47/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0731 - val_loss: 0.0727\n",
      "Epoch 48/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 34ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 49/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 50/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 51/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 52/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 53/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 54/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 55/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 56/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 57/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 58/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 32ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 59/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 36ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 60/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 35ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 61/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 41ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 62/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 34ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 63/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 36ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 64/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 65/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 66/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 67/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0726\n",
      "Epoch 68/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 69/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 70/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 71/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 72/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 28ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 73/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 74/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 31ms/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 75/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 26ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 76/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 24ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 77/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 26ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 78/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 79/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 26ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 80/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 28ms/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 81/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 82/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 28ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 83/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 84/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 85/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 86/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 28ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 87/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 88/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 28ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 89/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 28ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 90/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 91/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 92/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 26ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 93/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0729 - val_loss: 0.0725\n",
      "Epoch 94/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 95/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 96/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 97/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 98/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 99/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 100/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 26ms/step - loss: 0.0730 - val_loss: 0.0726\n",
      "Epoch 101/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 26ms/step - loss: 0.0729 - val_loss: 0.0725\n",
      "Epoch 102/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 103/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 104/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 105/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0729 - val_loss: 0.0725\n",
      "Epoch 106/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 107/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 108/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0729 - val_loss: 0.0725\n",
      "Epoch 109/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0726\n",
      "Epoch 110/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 30ms/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 111/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 112/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 113/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 29ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 114/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 115/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 116/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 26ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 117/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 118/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 119/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 120/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - 0s 25ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 121/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 23ms/step - loss: 0.0729 - val_loss: 0.0725\n",
      "Epoch 122/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 25ms/step - loss: 0.0730 - val_loss: 0.0726\n",
      "Epoch 123/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - 0s 27ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 124/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 125/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 126/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 127/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0729 - val_loss: 0.0725\n",
      "Epoch 128/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 129/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 130/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0724\n",
      "Epoch 131/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 132/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 133/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 134/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0728 - val_loss: 0.0724\n",
      "Epoch 135/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0728 - val_loss: 0.0724\n",
      "Epoch 136/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 137/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 138/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0728 - val_loss: 0.0724\n",
      "Epoch 139/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0729 - val_loss: 0.0722\n",
      "Epoch 140/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 141/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 142/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 143/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 144/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 145/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 146/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 147/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 148/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 149/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0728 - val_loss: 0.0724\n",
      "Epoch 150/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 151/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 152/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 153/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0724\n",
      "Epoch 154/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 32ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 155/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 156/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 157/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 158/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 159/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 160/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 161/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 162/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 163/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0728 - val_loss: 0.0724\n",
      "Epoch 164/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 165/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 166/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 167/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 168/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 34ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 169/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0727 - val_loss: 0.0723\n",
      "Epoch 170/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0727 - val_loss: 0.0723\n",
      "Epoch 171/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0727 - val_loss: 0.0723\n",
      "Epoch 172/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 173/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 174/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 175/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 176/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 177/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 178/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 179/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 180/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 181/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 182/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0727 - val_loss: 0.0723\n",
      "Epoch 183/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 184/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 185/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0723\n",
      "Epoch 186/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 187/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 188/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 189/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 190/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 191/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 192/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 193/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 194/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 195/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 196/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 197/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0727 - val_loss: 0.0723\n",
      "Epoch 198/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 199/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 200/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 201/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 202/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0727 - val_loss: 0.0724\n",
      "Epoch 203/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 204/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 205/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 206/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 207/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 208/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 209/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 210/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 211/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 212/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 213/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 214/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 215/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 216/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 217/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 218/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 219/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 220/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 221/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0727 - val_loss: 0.0722\n",
      "Epoch 222/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 223/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 224/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0723\n",
      "Epoch 225/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 226/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 227/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 228/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 229/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 230/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 231/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 232/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 233/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 234/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0726 - val_loss: 0.0723\n",
      "Epoch 235/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 236/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0727 - val_loss: 0.0723\n",
      "Epoch 237/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 238/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 239/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0720\n",
      "Epoch 240/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 241/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 242/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 243/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 244/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 245/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0726 - val_loss: 0.0723\n",
      "Epoch 246/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 247/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 248/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 249/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 250/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0722\n",
      "Epoch 251/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 252/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 253/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 254/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 32ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 255/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 32ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 256/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 257/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 258/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 259/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 260/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 261/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 262/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 263/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 264/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 265/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 266/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 267/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 268/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 269/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 270/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0725 - val_loss: 0.0722\n",
      "Epoch 271/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 272/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 273/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 274/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 275/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 276/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 277/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 34ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 278/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0720\n",
      "Epoch 279/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 280/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 281/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 282/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0726 - val_loss: 0.0720\n",
      "Epoch 283/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 284/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 285/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 286/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 287/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 288/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 289/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0722\n",
      "Epoch 290/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0726 - val_loss: 0.0720\n",
      "Epoch 291/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 292/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 293/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0722\n",
      "Epoch 294/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 295/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 296/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 297/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0722\n",
      "Epoch 298/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 299/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 300/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 301/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 302/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 303/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 304/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 305/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 306/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 307/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 308/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 309/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 310/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 311/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 312/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0726 - val_loss: 0.0720\n",
      "Epoch 313/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 314/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 33ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 315/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 316/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 317/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 318/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 319/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 320/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 321/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 322/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 323/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 324/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 325/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 326/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 327/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 328/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 329/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 330/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 331/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 332/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 333/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 334/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 335/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 336/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 337/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 338/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 339/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 340/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 341/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 342/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 343/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 344/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 345/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 346/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 347/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 348/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 349/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 350/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 351/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 352/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 353/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0724 - val_loss: 0.0722\n",
      "Epoch 354/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 355/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0721\n",
      "Epoch 356/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 357/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0725 - val_loss: 0.0720\n",
      "Epoch 358/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 359/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 360/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 361/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 362/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 363/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 364/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 365/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 366/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 367/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0724 - val_loss: 0.0722\n",
      "Epoch 368/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 369/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 32ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 370/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 371/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 372/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 32ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 373/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 35ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 374/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 375/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 376/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 377/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 378/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 379/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 380/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 381/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 382/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 383/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0724 - val_loss: 0.0722\n",
      "Epoch 384/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 385/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 386/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 387/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 388/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 38ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 389/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 40ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 390/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 391/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 392/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 393/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 394/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 395/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 396/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 397/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 398/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 399/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 400/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 401/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 402/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 403/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 34ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 404/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 405/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 406/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 407/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 408/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 409/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 410/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 411/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 412/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 413/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0722 - val_loss: 0.0719\n",
      "Epoch 414/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 415/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 416/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 417/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 418/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0723 - val_loss: 0.0719\n",
      "Epoch 419/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 420/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 421/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 422/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 423/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 424/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 425/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 426/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 427/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 22ms/step - loss: 0.0722 - val_loss: 0.0719\n",
      "Epoch 428/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 429/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 430/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 431/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 432/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0722 - val_loss: 0.0719\n",
      "Epoch 433/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 434/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 435/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 1s 52ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 436/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 437/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 438/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 439/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 440/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0723 - val_loss: 0.0719\n",
      "Epoch 441/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 442/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 443/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 444/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 445/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 446/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 447/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 448/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 449/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0722 - val_loss: 0.0722\n",
      "Epoch 450/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 451/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 452/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0721 - val_loss: 0.0721\n",
      "Epoch 453/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 454/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 455/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 456/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 457/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 458/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 459/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 460/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 461/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0721 - val_loss: 0.0721\n",
      "Epoch 462/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 463/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 464/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0722 - val_loss: 0.0719\n",
      "Epoch 465/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 466/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 467/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 34ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 468/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 469/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 470/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 471/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0723 - val_loss: 0.0720\n",
      "Epoch 472/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 473/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 474/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 475/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 476/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 477/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 478/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 479/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 480/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 481/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 482/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 483/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 484/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 485/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 486/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 1s 54ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 487/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 488/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 489/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 490/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 34ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 491/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 1s 48ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 492/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 1s 48ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 493/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 494/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 495/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 496/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 39ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 497/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 1s 51ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 498/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 1s 46ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 499/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 41ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 500/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 501/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 36ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 502/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 38ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 503/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 1s 47ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 504/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 38ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 505/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 38ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 506/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 32ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 507/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 508/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 509/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 510/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 511/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0721 - val_loss: 0.0721\n",
      "Epoch 512/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 513/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 514/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0721 - val_loss: 0.0721\n",
      "Epoch 515/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 516/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 517/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 33ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 518/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 32ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 519/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 35ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 520/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 521/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 522/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 523/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 524/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 525/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 526/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 527/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 528/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 529/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 530/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 531/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 532/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 533/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 534/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0721\n",
      "Epoch 535/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 536/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 537/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 538/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 539/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 540/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 541/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 542/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 39ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 543/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 38ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 544/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 545/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 34ms/step - loss: 0.0722 - val_loss: 0.0720\n",
      "Epoch 546/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 1s 44ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 547/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 33ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 548/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 36ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 549/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 550/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 39ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 551/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 36ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 552/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 1s 49ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 553/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 36ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 554/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 33ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 555/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 556/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 557/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 558/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 559/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 32ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 560/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 561/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 562/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 563/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 33ms/step - loss: 0.0720 - val_loss: 0.0721\n",
      "Epoch 564/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 565/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 566/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 567/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 568/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 569/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 570/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 571/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 33ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 572/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 573/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 574/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 575/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 576/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 577/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 578/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 579/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 580/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 581/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 1s 43ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 582/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 583/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 584/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 585/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 586/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 587/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 588/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 589/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0721\n",
      "Epoch 590/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0721\n",
      "Epoch 591/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 592/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 33ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 593/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 594/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 595/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 596/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 597/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 598/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 599/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 600/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 601/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 602/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 37ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 603/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 33ms/step - loss: 0.0720 - val_loss: 0.0721\n",
      "Epoch 604/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 41ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 605/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 33ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 606/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 607/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 608/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 609/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 610/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 611/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 612/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 31ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 613/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 614/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0719 - val_loss: 0.0723\n",
      "Epoch 615/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 616/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 617/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 33ms/step - loss: 0.0720 - val_loss: 0.0721\n",
      "Epoch 618/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 32ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 619/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 36ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 620/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 621/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 622/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 623/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 624/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 625/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 626/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 627/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 628/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 629/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 630/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 631/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 30ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 632/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 633/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0721\n",
      "Epoch 634/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0721 - val_loss: 0.0720\n",
      "Epoch 635/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 636/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 637/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 638/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 32ms/step - loss: 0.0720 - val_loss: 0.0721\n",
      "Epoch 639/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 640/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 641/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 642/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 643/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 644/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 645/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0721\n",
      "Epoch 646/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0721\n",
      "Epoch 647/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 648/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 649/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 650/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 651/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 23ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 652/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 653/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 654/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 655/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 656/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 657/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 658/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 659/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 660/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 661/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 662/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 663/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 664/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 665/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 666/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 667/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 668/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 669/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 670/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 671/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 672/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 29ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 673/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 674/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 675/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 676/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 1s 51ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 677/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 678/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 679/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 680/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 681/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 682/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 683/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 684/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0720 - val_loss: 0.0720\n",
      "Epoch 685/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 686/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 32ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 687/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 688/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 27ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 689/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 690/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0721\n",
      "Epoch 691/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 692/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 693/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 694/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 695/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 32ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 696/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 697/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 698/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 699/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 700/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 701/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0719 - val_loss: 0.0721\n",
      "Epoch 702/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 703/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 704/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 705/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 706/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 707/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 708/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 709/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 28ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 710/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 711/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0721\n",
      "Epoch 712/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 713/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 714/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 715/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 716/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 717/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 718/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 719/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 720/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 721/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 722/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 723/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 724/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 725/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 726/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0719 - val_loss: 0.0719\n",
      "Epoch 727/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 728/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 729/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 730/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 731/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 732/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 32ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 733/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 32ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 734/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 735/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 736/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 33ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 737/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 738/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 739/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 740/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 741/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 742/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 743/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 744/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 745/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 746/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 747/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 748/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 749/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 750/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 751/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 752/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 753/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 754/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 755/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0719 - val_loss: 0.0720\n",
      "Epoch 756/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 757/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 758/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 759/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 760/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 761/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 762/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 763/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 764/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 765/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 766/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 767/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 768/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 769/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 770/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 771/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 772/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 773/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 774/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 775/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 776/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 777/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 778/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 779/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 780/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 781/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 782/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 783/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 784/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 785/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 786/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 787/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 788/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 789/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 790/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 791/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 792/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 793/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 794/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 795/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 796/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 797/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 798/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 799/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 800/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 801/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 802/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 803/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 804/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 805/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 806/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 807/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 808/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 809/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 810/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 811/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 812/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 813/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 814/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 35ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 815/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 816/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 817/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 818/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 819/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 820/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 821/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 822/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 823/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 824/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 825/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 826/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 827/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 828/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 829/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 830/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 831/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 33ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 832/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0721\n",
      "Epoch 833/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 834/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 835/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 836/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 837/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 838/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 839/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 840/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 841/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0718 - val_loss: 0.0719\n",
      "Epoch 842/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 843/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0718 - val_loss: 0.0721\n",
      "Epoch 844/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 845/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 846/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 847/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 848/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 849/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 850/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 851/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 852/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 853/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 854/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 38ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 855/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 856/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 857/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 858/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 859/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 860/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 861/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 862/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0718 - val_loss: 0.0720\n",
      "Epoch 863/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 864/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 865/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 866/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 867/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 868/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 869/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 870/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 871/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 872/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 873/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 874/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 875/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 876/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 877/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 878/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 879/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 880/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0721\n",
      "Epoch 881/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 882/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 883/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 884/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 885/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 886/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 887/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 888/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 889/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 890/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 891/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 892/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 893/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 894/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 895/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 896/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 897/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 898/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 899/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 900/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 901/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 902/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 903/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 904/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 905/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 906/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 39ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 907/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 908/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 909/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 910/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0721\n",
      "Epoch 911/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 912/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 913/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 914/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 915/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 916/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 917/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0721\n",
      "Epoch 918/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 919/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 920/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 921/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 922/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 923/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 924/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 925/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 926/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 927/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 928/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0717 - val_loss: 0.0719\n",
      "Epoch 929/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 930/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 931/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 932/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 933/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 934/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 935/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 936/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 937/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 938/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 939/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 940/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 941/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 942/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 943/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 944/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 945/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 946/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 947/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 948/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 33ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 949/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 33ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 950/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 951/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 952/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 953/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 954/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 955/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 956/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 957/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 958/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 959/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 960/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 961/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 962/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 963/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 964/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 965/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 966/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 967/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 968/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 969/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 970/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 971/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0721\n",
      "Epoch 972/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 973/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 974/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 975/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 976/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 977/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 978/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 979/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 980/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 981/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 982/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 983/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 984/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 985/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 986/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 987/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 988/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 989/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 990/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 35ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 991/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 32ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 992/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 993/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 994/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 995/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 996/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 997/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 998/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 999/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1000/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1001/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1002/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1003/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1004/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1005/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1006/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1007/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1008/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1009/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1010/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1011/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 1012/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1013/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1014/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1015/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1016/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1017/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1018/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1019/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1020/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1021/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1022/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1023/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1024/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1025/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0716 - val_loss: 0.0721\n",
      "Epoch 1026/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1027/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1028/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 34ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1029/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1030/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 32ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1031/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1032/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 33ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1033/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1034/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1035/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1036/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 36ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1037/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 35ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1038/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 36ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1039/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 34ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1040/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 1s 47ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1041/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 32ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1042/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1043/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1044/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1045/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1046/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1047/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 35ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1048/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 34ms/step - loss: 0.0716 - val_loss: 0.0720\n",
      "Epoch 1049/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 32ms/step - loss: 0.0715 - val_loss: 0.0721\n",
      "Epoch 1050/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 34ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1051/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1052/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 33ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1053/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 35ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1054/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1055/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 37ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1056/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 1s 42ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1057/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 1s 43ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1058/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 33ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1059/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 34ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1060/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1061/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1062/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1063/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1064/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1065/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1066/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 37ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1067/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 32ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1068/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1069/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1070/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1071/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1072/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 34ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1073/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1074/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1075/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1076/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1077/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1078/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 31ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1079/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1080/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1081/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1082/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1083/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0721\n",
      "Epoch 1084/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1085/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1086/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1087/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1088/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1089/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1090/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1091/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1092/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1093/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1094/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1095/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1096/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 35ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1097/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1098/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1099/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1100/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1101/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1102/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1103/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 1104/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1105/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1106/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 33ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1107/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1108/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1109/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1110/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1111/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1112/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1113/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1114/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1115/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1116/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0721\n",
      "Epoch 1117/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1118/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0716 - val_loss: 0.0719\n",
      "Epoch 1119/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1120/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1121/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1122/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1123/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1124/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1125/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1126/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1127/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 34ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1128/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1129/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1130/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1131/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1132/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1133/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1134/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1135/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1136/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1137/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 30ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1138/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1139/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1140/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1141/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1142/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1143/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1144/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1145/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1146/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1147/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0719\n",
      "Epoch 1148/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1149/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1150/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0719\n",
      "Epoch 1151/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1152/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1153/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1154/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1155/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1156/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1157/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1158/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1159/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1160/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1161/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1162/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0719\n",
      "Epoch 1163/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1164/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1165/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1166/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1167/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1168/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1169/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1170/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1171/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1172/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1173/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1174/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1175/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1176/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1177/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1178/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1179/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1180/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1181/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1182/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1183/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1184/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1185/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1186/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1187/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1188/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1189/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1190/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1191/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1192/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0720\n",
      "Epoch 1193/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1194/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1195/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1196/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1197/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1198/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1199/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1200/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1201/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1202/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1203/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1204/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1205/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1206/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1207/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0713 - val_loss: 0.0722\n",
      "Epoch 1208/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1209/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1210/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1211/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1212/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1213/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1214/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1215/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1216/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1217/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1218/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1219/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 1220/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1221/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1222/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1223/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1224/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1225/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1226/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1227/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1228/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1229/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1230/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1231/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1232/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1233/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1234/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1235/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.073 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1236/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1237/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1238/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1239/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1240/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1241/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1242/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1243/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1244/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1245/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1246/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1247/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1248/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1249/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1250/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1251/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1252/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1253/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1254/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1255/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1256/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1257/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1258/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1259/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1260/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1261/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1262/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1263/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1264/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1265/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0715 - val_loss: 0.0721\n",
      "Epoch 1266/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1267/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1268/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1269/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1270/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1271/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1272/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0720\n",
      "Epoch 1273/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1274/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1275/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1276/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1277/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1278/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1279/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1280/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1281/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1282/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1283/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1284/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1285/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1286/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1287/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1288/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1289/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1290/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1291/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1292/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1293/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 29ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1294/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1295/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1296/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1297/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1298/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1299/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1300/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1301/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1302/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1303/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1304/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1305/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1306/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1307/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1308/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1309/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1310/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1311/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1312/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1313/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1314/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1315/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1316/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1317/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1318/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 28ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1319/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1320/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1321/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1322/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1323/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1324/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1325/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1326/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1327/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1328/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1329/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1330/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1331/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 1332/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1333/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1334/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1335/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1336/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1337/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1338/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1339/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1340/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1341/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1342/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 33ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1343/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1344/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1345/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1346/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1347/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1348/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 26ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1349/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1350/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1351/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1352/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1353/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1354/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1355/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1356/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1357/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1358/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1359/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1360/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1361/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1362/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0711 - val_loss: 0.0721\n",
      "Epoch 1363/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1364/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1365/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1366/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1367/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1368/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0720\n",
      "Epoch 1369/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1370/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1371/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 27ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1372/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1373/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0711 - val_loss: 0.0721\n",
      "Epoch 1374/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1375/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1376/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1377/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1378/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1379/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1380/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1381/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1382/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1383/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1384/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0711 - val_loss: 0.0721\n",
      "Epoch 1385/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1386/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1387/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1388/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 22ms/step - loss: 0.0712 - val_loss: 0.0720\n",
      "Epoch 1389/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 25ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1390/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1391/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0713 - val_loss: 0.0721\n",
      "Epoch 1392/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 23ms/step - loss: 0.0712 - val_loss: 0.0721\n",
      "Epoch 1393/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - 0s 24ms/step - loss: 0.0711 - val_loss: 0.0721\n",
      "Epoch 1394/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 35ms/step - loss: 0.0707 - val_loss: 0.0723\n",
      "Epoch 2530/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 33ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2531/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 29ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2532/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 30ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2533/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0707 - val_loss: 0.0723\n",
      "Epoch 2534/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2535/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0708 - val_loss: 0.0724\n",
      "Epoch 2536/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 31ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2537/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2538/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2539/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0707 - val_loss: 0.0723\n",
      "Epoch 2540/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2541/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2542/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2543/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2544/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2545/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2546/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2547/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 30ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2548/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2549/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2550/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 31ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2551/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 32ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2552/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 30ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2553/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 31ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2554/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2555/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2556/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2557/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 30ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2558/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2559/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2560/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2561/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 34ms/step - loss: 0.0706 - val_loss: 0.0725\n",
      "Epoch 2562/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 29ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2563/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 30ms/step - loss: 0.0707 - val_loss: 0.0723\n",
      "Epoch 2564/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 34ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2565/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2566/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2567/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2568/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 29ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2569/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 29ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2570/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0704 - val_loss: 0.0724\n",
      "Epoch 2571/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2572/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2573/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2574/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0705 - val_loss: 0.0723\n",
      "Epoch 2575/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.068 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0707 - val_loss: 0.0725\n",
      "Epoch 2576/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2577/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0707 - val_loss: 0.0725\n",
      "Epoch 2578/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 30ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2579/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2580/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 39ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2581/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 33ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2582/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 29ms/step - loss: 0.0707 - val_loss: 0.0723\n",
      "Epoch 2583/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 31ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2584/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 29ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2585/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 29ms/step - loss: 0.0706 - val_loss: 0.0725\n",
      "Epoch 2586/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2587/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2588/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 31ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2589/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0725\n",
      "Epoch 2590/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2591/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2592/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2593/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2594/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2595/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2596/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0707 - val_loss: 0.0723\n",
      "Epoch 2597/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2598/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2599/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2600/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2601/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2602/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.068 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 30ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2603/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0707 - val_loss: 0.0724\n",
      "Epoch 2604/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.07 - 0s 23ms/step - loss: 0.0704 - val_loss: 0.0725\n",
      "Epoch 2911/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0704 - val_loss: 0.0725\n",
      "Epoch 2912/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2913/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2914/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2915/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2916/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0704 - val_loss: 0.0724\n",
      "Epoch 2917/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0704 - val_loss: 0.0725\n",
      "Epoch 2918/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2919/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2920/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2921/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2922/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0726\n",
      "Epoch 2923/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0706 - val_loss: 0.0725\n",
      "Epoch 2924/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0706 - val_loss: 0.0725\n",
      "Epoch 2925/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2926/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2927/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2928/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2929/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2930/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0704 - val_loss: 0.0725\n",
      "Epoch 2931/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2932/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 29ms/step - loss: 0.0704 - val_loss: 0.0725\n",
      "Epoch 2933/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2934/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2935/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 33ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2936/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0704 - val_loss: 0.0724\n",
      "Epoch 2937/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2938/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2939/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 28ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2940/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0726\n",
      "Epoch 2941/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2942/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2943/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0704 - val_loss: 0.0727\n",
      "Epoch 2944/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0706 - val_loss: 0.0723\n",
      "Epoch 2945/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2946/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0705 - val_loss: 0.0723\n",
      "Epoch 2947/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2948/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2949/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2950/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0704 - val_loss: 0.0724\n",
      "Epoch 2951/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2952/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2953/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2954/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2955/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2956/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2957/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2958/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 22ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2959/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2960/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0704 - val_loss: 0.0724\n",
      "Epoch 2961/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0704 - val_loss: 0.0726\n",
      "Epoch 2962/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0704 - val_loss: 0.0725\n",
      "Epoch 2963/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0706 - val_loss: 0.0724\n",
      "Epoch 2964/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2965/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2966/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0704 - val_loss: 0.0725\n",
      "Epoch 2967/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0704 - val_loss: 0.0724\n",
      "Epoch 2968/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2969/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2970/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.072 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2971/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2972/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 29ms/step - loss: 0.0704 - val_loss: 0.0724\n",
      "Epoch 2973/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 27ms/step - loss: 0.0704 - val_loss: 0.0724\n",
      "Epoch 2974/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2975/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2976/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2977/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2978/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2979/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0725\n",
      "Epoch 2980/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 25ms/step - loss: 0.0706 - val_loss: 0.0725\n",
      "Epoch 2981/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 23ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2982/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2983/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2984/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 36ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2985/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 30ms/step - loss: 0.0705 - val_loss: 0.0725\n",
      "Epoch 2986/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2987/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0704 - val_loss: 0.0725\n",
      "Epoch 2988/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2989/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.068 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 30ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2990/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 26ms/step - loss: 0.0704 - val_loss: 0.0724\n",
      "Epoch 2991/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 22ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2992/3000\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - 0s 24ms/step - loss: 0.0705 - val_loss: 0.0724\n",
      "Epoch 2993/3000\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.070"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Dense(100, activation='relu',\n",
    "                      input_shape=(len(feature_names),),\n",
    "                      kernel_initializer=initializers.he_normal(seed=0)))\n",
    "model.add(layers.Dense(100, activation='relu',\n",
    "                      kernel_initializer=initializers.he_normal(seed=0)))\n",
    "model.add(layers.Dropout(0.7))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=\"adam\",)\n",
    "\n",
    "print('start fitting')\n",
    "history = model.fit(dataset_train[feature_names], dataset_train['rank'],\n",
    "                    batch_size=10000, #1000\n",
    "                    epochs=3000, #225\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['val_loss'][1:])\n",
    "plt.plot(history.history['loss'][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "cf = lgb.LGBMRegressor(n_estimators=500)\n",
    "cf.fit(dataset_train[feature_names].astype(float), dataset_train['rank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cf2 = RandomForestRegressor(n_estimators=100)\n",
    "cf2.fit(dataset_train[feature_names].astype(float), dataset_train['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Value', ylabel='Feature'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_imp = pd.DataFrame(zip(cf.feature_importances_, feature_names), \n",
    "                           columns=['Value','Feature']).sort_values('Value', ascending=False)\n",
    "feature_imp\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Miniconda3\\envs\\finlab\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\ProgramData\\Miniconda3\\envs\\finlab\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "D:\\ProgramData\\Miniconda3\\envs\\finlab\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "dataset_drop = dataset.dropna(subset=feature_names+['return'])\n",
    "\n",
    "vals = model.predict(dataset_drop[feature_names].astype(float))\n",
    "dataset_drop['result1'] = pd.Series(vals.swapaxes(0,1)[0], dataset_drop.index)\n",
    "\n",
    "vals = cf.predict(dataset_drop[feature_names].astype(float))\n",
    "dataset_drop['result2'] = pd.Series(vals, dataset_drop.index)\n",
    "\n",
    "vals = cf2.predict(dataset_drop[feature_names].astype(float))\n",
    "dataset_drop['result3'] = pd.Series(vals, dataset_drop.index)\n",
    "\n",
    "dataset_drop = dataset_drop.reset_index().set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "dates = sorted(list(set(dataset_drop.index)))\n",
    "\n",
    "rs = []\n",
    "for d in dates:\n",
    "    \n",
    "    dataset_time = dataset_drop.loc[d]\n",
    "    \n",
    "    dataset_time = drop_extreme_case(dataset_time,list1, thresh=0.01)\n",
    "    \n",
    "    rank = dataset_time['result1'] + dataset_time['result2'] + dataset_time['result3'] \n",
    "    \n",
    "    condition = (rank >= rank.nlargest(20).iloc[-1]) \n",
    "    r = dataset_time['return'][condition].mean()\n",
    "\n",
    "    rs.append(r * (1-3/1000-1.425/1000*2*0.6))\n",
    "\n",
    "rs = pd.Series(rs, index=dates)['2022':].cumprod()\n",
    "\n",
    "s0050 = close['0050']['2022':]\n",
    "\n",
    "pd.DataFrame({'nn strategy return':rs.reindex(s0050.index, method='ffill'), '0050 return':s0050/s0050[0]}).plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 當月持股狀況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2005-02-15', '2005-03-15', '2005-04-15', '2005-05-15',\n",
       "               '2005-06-15', '2005-07-15', '2005-08-15', '2005-09-15',\n",
       "               '2005-10-15', '2005-11-15',\n",
       "               ...\n",
       "               '2022-01-15', '2022-02-15', '2022-03-15', '2022-04-15',\n",
       "               '2022-05-15', '2022-06-15', '2022-07-15', '2022-08-15',\n",
       "               '2022-09-15', '2022-10-15'],\n",
       "              dtype='datetime64[ns]', name='date', length=213, freq=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.index.levels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the latest dataset\n",
    "last_date = \"2022-09-15\"#dataset.index.levels[1].max()\n",
    "is_last_date = dataset.index.get_level_values('date') == last_date\n",
    "last_dataset = dataset[is_last_date].copy()\n",
    "\n",
    "\n",
    "last_dataset = drop_extreme_case(last_dataset,list1, thresh=0.01)\n",
    "\n",
    "\n",
    "# remove NaN testcases\n",
    "last_dataset = last_dataset.dropna(subset=feature_names)\n",
    "\n",
    "# predict\n",
    "\n",
    "vals = model.predict(last_dataset[feature_names].astype(float))\n",
    "last_dataset['result1'] = pd.Series(vals.swapaxes(0,1)[0], last_dataset.index)\n",
    "\n",
    "vals = cf.predict(last_dataset[feature_names].astype(float))\n",
    "last_dataset['result2'] = pd.Series(vals, last_dataset.index)\n",
    "\n",
    "vals = cf2.predict(last_dataset[feature_names].astype(float))\n",
    "last_dataset['result3'] = pd.Series(vals, last_dataset.index)\n",
    "\n",
    "# calculate score\n",
    "\n",
    "rank = last_dataset['result1'] + last_dataset['result2'] + last_dataset['result3']\n",
    "condition = (rank >= rank.nlargest(20).iloc[-1]) \n",
    "\n",
    "# plot rank distribution\n",
    "rank.hist(bins=20)\n",
    "\n",
    "\n",
    "# show the best 20 stocks\n",
    "slist1 = rank[condition].reset_index()['stock_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 平均分配資產於股票之中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "股票平分張數:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stock_id\n",
       "2206    0.189633\n",
       "2358    0.506757\n",
       "2421    0.192802\n",
       "2471    0.282486\n",
       "2637    0.127334\n",
       "2643    0.109012\n",
       "3231    0.279851\n",
       "3501    0.160428\n",
       "3611    0.040107\n",
       "3679    0.088757\n",
       "3704         NaN\n",
       "4417    0.206044\n",
       "4506    0.101488\n",
       "4958    0.068807\n",
       "5403    0.109810\n",
       "5493    0.141777\n",
       "6139    0.246711\n",
       "6184    0.155763\n",
       "8342    0.138376\n",
       "9924    0.182260\n",
       "Name: 2022-10-07 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close = data.get(\"收盤價\")\n",
    "\n",
    "money = 50000*3\n",
    "stock_prices = close[rank[condition].reset_index()['stock_id']].iloc[-1]\n",
    "\n",
    "\n",
    "print(\"股票平分張數:\")\n",
    "money / len(stock_prices) / stock_prices / 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finlab",
   "language": "python",
   "name": "finlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
