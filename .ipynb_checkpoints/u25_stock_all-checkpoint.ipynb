{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 獲取歷史資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finlab.data import Data\n",
    "\n",
    "data = Data()\n",
    "\n",
    "rev = data.get(\"當月營收\")\n",
    "close = data.get(\"收盤價\")\n",
    "\n",
    "\n",
    "rev.index = rev.index.shift(5, \"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(n):\n",
    "    return close / close.rolling(n, min_periods=1).mean()\n",
    "\n",
    "def acc(n):\n",
    "    return close.shift(n) / (close.shift(2*n) + close) * 2\n",
    "\n",
    "def rsv(n):\n",
    "    l = close.rolling(n, min_periods=1).min()\n",
    "    h = close.rolling(n, min_periods=1).max()\n",
    "    \n",
    "    return (close - l) / (h - l)\n",
    "\n",
    "def mom(n):\n",
    "    return (rev / rev.shift(1)).shift(n)\n",
    "\n",
    "def yoy(n):\n",
    "    return (rev / rev.shift(12)).shift(n)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features = {\n",
    "    'mom1': mom(1),\n",
    "    'mom2': mom(2),\n",
    "    'mom3': mom(3),\n",
    "    'mom4': mom(4),\n",
    "    'mom5': mom(5),\n",
    "    'mom6': mom(6),\n",
    "    'mom7': mom(7),\n",
    "    'mom8': mom(8),\n",
    "    'mom9': mom(9),\n",
    "    \n",
    "    'yoy':yoy(1),\n",
    "    'delta_yoy':yoy(1)-yoy(2),\n",
    "    \n",
    "    'bias5': bias(5),\n",
    "    'bias10': bias(10),\n",
    "    'bias20': bias(20),\n",
    "    'bias60': bias(60),\n",
    "    'bias120': bias(120),\n",
    "    'bias240': bias(240),\n",
    "    \n",
    "    'acc5': acc(5),\n",
    "    'acc10': acc(10),\n",
    "    'acc20': acc(20),\n",
    "    'acc60': acc(60),\n",
    "    'acc120': acc(120),\n",
    "    'acc240': acc(240),\n",
    "    \n",
    "    'rsv5': rsv(5),\n",
    "    'rsv10': rsv(10),\n",
    "    'rsv20': rsv(20),\n",
    "    'rsv60': rsv(60),\n",
    "    'rsv120': rsv(120),\n",
    "    'rsv240': rsv(240),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 製作dataset\n",
    "\n",
    "##### 設定買賣頻率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2005-02-15', '2005-03-15', '2005-04-15', '2005-05-15',\n",
       "               '2005-06-15', '2005-07-15', '2005-08-15', '2005-09-15',\n",
       "               '2005-10-15', '2005-11-15',\n",
       "               ...\n",
       "               '2021-10-15', '2021-11-15', '2021-12-15', '2022-01-15',\n",
       "               '2022-02-15', '2022-03-15', '2022-04-15', '2022-05-15',\n",
       "               '2022-06-15', '2022-07-15'],\n",
       "              dtype='datetime64[ns]', name='date', length=210, freq=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "every_month = rev.index\n",
    "every_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 將dataframe 組裝起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features['bias20'].reindex(every_month, method='ffill')\n",
    "\n",
    "for name, f in features.items():\n",
    "    features[name] = f.reindex(every_month, method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, f in features.items():\n",
    "    features[name] = f.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finlab import ml\n",
    "\n",
    "ml.add_profit_prediction(dataset)\n",
    "ml.add_rank_prediction(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 刪除太大太小的歷史資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425880, 31)\n",
      "(396123, 31)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "\n",
    "def drop_extreme_case(dataset, feature_names, thresh=0.01):\n",
    "    \n",
    "    extreme_cases = pd.Series(False, index=dataset.index)\n",
    "    for f in feature_names:\n",
    "        tf = dataset[f]\n",
    "        extreme_cases = extreme_cases | (tf < tf.quantile(thresh)) | (tf > tf.quantile(1-thresh))\n",
    "    dataset = dataset[~extreme_cases]\n",
    "    return dataset\n",
    "\n",
    "dataset_drop_extreme_case = drop_extreme_case(dataset, \n",
    "    ['bias60', 'bias120', 'bias240', 'mom1', 'mom2', 'mom3', 'mom4', 'mom5', 'mom6','yoy','delta_yoy'], thresh=0.01)\n",
    "\n",
    "print(dataset_drop_extreme_case.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dropna = dataset_drop_extreme_case.dropna(how='any')\n",
    "dataset_dropna = dataset_dropna.reset_index().set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2005-02-15', '2005-03-15', '2005-04-15', '2005-05-15',\n",
       "               '2005-06-15', '2005-07-15', '2005-08-15', '2005-09-15',\n",
       "               '2005-10-15', '2005-11-15',\n",
       "               ...\n",
       "               '2021-10-15', '2021-11-15', '2021-12-15', '2022-01-15',\n",
       "               '2022-02-15', '2022-03-15', '2022-04-15', '2022-05-15',\n",
       "               '2022-06-15', '2022-07-15'],\n",
       "              dtype='datetime64[ns]', name='date', length=396123, freq=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_drop_extreme_case.index.get_level_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_dropna.loc[:'2017']\n",
    "dataset_test = dataset_dropna.loc['2018':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神經網路模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               3000      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 13,201\n",
      "Trainable params: 13,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "start fitting\n",
      "Train on 105894 samples, validate on 11766 samples\n",
      "Epoch 1/5000\n",
      "105894/105894 [==============================] - ETA: 26s - loss: 0.17 - ETA: 11s - loss: 0.17 - ETA: 4s - loss: 0.1708 - ETA: 3s - loss: 0.167 - ETA: 1s - loss: 0.162 - ETA: 1s - loss: 0.159 - ETA: 0s - loss: 0.156 - ETA: 0s - loss: 0.153 - 3s 32us/sample - loss: 0.1523 - val_loss: 0.0827\n",
      "Epoch 2/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.118 - ETA: 0s - loss: 0.116 - ETA: 0s - loss: 0.115 - ETA: 0s - loss: 0.113 - ETA: 0s - loss: 0.111 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.108 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.103 - 1s 6us/sample - loss: 0.1030 - val_loss: 0.0801\n",
      "Epoch 3/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.088 - ETA: 0s - loss: 0.087 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.085 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - ETA: 0s - loss: 0.084 - 1s 6us/sample - loss: 0.0841 - val_loss: 0.0797\n",
      "Epoch 4/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - 1s 7us/sample - loss: 0.0806 - val_loss: 0.0797\n",
      "Epoch 5/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - 1s 6us/sample - loss: 0.0801 - val_loss: 0.0797\n",
      "Epoch 6/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0798 - val_loss: 0.0797\n",
      "Epoch 7/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0797 - val_loss: 0.0797\n",
      "Epoch 8/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0796 - val_loss: 0.0796\n",
      "Epoch 9/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0796 - val_loss: 0.0796\n",
      "Epoch 10/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0795 - val_loss: 0.0797\n",
      "Epoch 11/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0796 - val_loss: 0.0797\n",
      "Epoch 12/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0795 - val_loss: 0.0796\n",
      "Epoch 13/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0795 - val_loss: 0.0795\n",
      "Epoch 14/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0794 - val_loss: 0.0796\n",
      "Epoch 15/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 7us/sample - loss: 0.0794 - val_loss: 0.0795\n",
      "Epoch 16/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0794 - val_loss: 0.0795\n",
      "Epoch 17/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0794 - val_loss: 0.0795\n",
      "Epoch 18/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 7us/sample - loss: 0.0793 - val_loss: 0.0795\n",
      "Epoch 19/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0794 - val_loss: 0.0795\n",
      "Epoch 20/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0794 - val_loss: 0.0795\n",
      "Epoch 21/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0793 - val_loss: 0.0794\n",
      "Epoch 22/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0793 - val_loss: 0.0794\n",
      "Epoch 23/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0793 - val_loss: 0.0794\n",
      "Epoch 24/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0793 - val_loss: 0.0794\n",
      "Epoch 25/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0792 - val_loss: 0.0793\n",
      "Epoch 26/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0793 - val_loss: 0.0794\n",
      "Epoch 27/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0792 - val_loss: 0.0793\n",
      "Epoch 28/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0792 - val_loss: 0.0793\n",
      "Epoch 29/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0792 - val_loss: 0.0793\n",
      "Epoch 30/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0792 - val_loss: 0.0793\n",
      "Epoch 31/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 7us/sample - loss: 0.0792 - val_loss: 0.0793\n",
      "Epoch 32/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0792 - val_loss: 0.0793\n",
      "Epoch 33/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0792 - val_loss: 0.0793\n",
      "Epoch 34/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0791 - val_loss: 0.0793\n",
      "Epoch 35/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0792 - val_loss: 0.0793\n",
      "Epoch 36/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0792 - val_loss: 0.0793\n",
      "Epoch 37/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0791 - val_loss: 0.0792\n",
      "Epoch 38/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0791 - val_loss: 0.0792\n",
      "Epoch 39/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0791 - val_loss: 0.0792\n",
      "Epoch 40/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0791 - val_loss: 0.0792\n",
      "Epoch 41/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0790 - val_loss: 0.0792\n",
      "Epoch 42/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0790 - val_loss: 0.0792\n",
      "Epoch 43/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0790 - val_loss: 0.0792\n",
      "Epoch 44/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0790 - val_loss: 0.0791\n",
      "Epoch 45/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 6us/sample - loss: 0.0790 - val_loss: 0.0792\n",
      "Epoch 46/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 7us/sample - loss: 0.0790 - val_loss: 0.0791\n",
      "Epoch 47/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0790 - val_loss: 0.0791\n",
      "Epoch 48/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0789 - val_loss: 0.0792\n",
      "Epoch 49/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0790 - val_loss: 0.0792\n",
      "Epoch 50/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0789 - val_loss: 0.0791\n",
      "Epoch 51/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0789 - val_loss: 0.0792\n",
      "Epoch 52/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0789 - val_loss: 0.0791\n",
      "Epoch 53/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - 1s 5us/sample - loss: 0.0789 - val_loss: 0.0791\n",
      "Epoch 54/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0789 - val_loss: 0.0791\n",
      "Epoch 55/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0789 - val_loss: 0.0791\n",
      "Epoch 56/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0789 - val_loss: 0.0790\n",
      "Epoch 57/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - 1s 7us/sample - loss: 0.0789 - val_loss: 0.0791\n",
      "Epoch 58/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 7us/sample - loss: 0.0789 - val_loss: 0.0790\n",
      "Epoch 59/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 7us/sample - loss: 0.0789 - val_loss: 0.0791\n",
      "Epoch 60/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0789 - val_loss: 0.0790\n",
      "Epoch 61/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0788 - val_loss: 0.0790\n",
      "Epoch 62/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 8us/sample - loss: 0.0788 - val_loss: 0.0790\n",
      "Epoch 63/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 10us/sample - loss: 0.0788 - val_loss: 0.0790\n",
      "Epoch 64/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 9us/sample - loss: 0.0788 - val_loss: 0.0791\n",
      "Epoch 65/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0788 - val_loss: 0.0790\n",
      "Epoch 66/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0788 - val_loss: 0.0790\n",
      "Epoch 67/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0787 - val_loss: 0.0790\n",
      "Epoch 68/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0788 - val_loss: 0.0790\n",
      "Epoch 69/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0788 - val_loss: 0.0790\n",
      "Epoch 70/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 71/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 7us/sample - loss: 0.0788 - val_loss: 0.0790\n",
      "Epoch 72/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0788 - val_loss: 0.0789\n",
      "Epoch 73/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 74/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0787 - val_loss: 0.0790\n",
      "Epoch 75/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 76/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 77/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 78/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 79/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 80/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 81/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 82/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 83/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0789\n",
      "Epoch 84/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 85/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 86/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0789\n",
      "Epoch 87/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 88/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 89/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 90/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 91/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 8us/sample - loss: 0.0787 - val_loss: 0.0789\n",
      "Epoch 92/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 93/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0786 - val_loss: 0.0789\n",
      "Epoch 94/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0786 - val_loss: 0.0789\n",
      "Epoch 95/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 96/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 97/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0785 - val_loss: 0.0788\n",
      "Epoch 98/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 99/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0785 - val_loss: 0.0788\n",
      "Epoch 100/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0785 - val_loss: 0.0789\n",
      "Epoch 101/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0785 - val_loss: 0.0788\n",
      "Epoch 102/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0786 - val_loss: 0.0789\n",
      "Epoch 103/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0785 - val_loss: 0.0788\n",
      "Epoch 104/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0786 - val_loss: 0.0788\n",
      "Epoch 105/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0785 - val_loss: 0.0788\n",
      "Epoch 106/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0786 - val_loss: 0.0787\n",
      "Epoch 107/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0785 - val_loss: 0.0788\n",
      "Epoch 108/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0785 - val_loss: 0.0788\n",
      "Epoch 109/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0785 - val_loss: 0.0788\n",
      "Epoch 110/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0785 - val_loss: 0.0788\n",
      "Epoch 111/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 112/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0785 - val_loss: 0.0787\n",
      "Epoch 113/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0785 - val_loss: 0.0787\n",
      "Epoch 114/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0788\n",
      "Epoch 115/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0784 - val_loss: 0.0788\n",
      "Epoch 116/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 117/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 118/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 119/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0788\n",
      "Epoch 120/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0784 - val_loss: 0.0788\n",
      "Epoch 121/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0784 - val_loss: 0.0788\n",
      "Epoch 122/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0785 - val_loss: 0.0787\n",
      "Epoch 123/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0788\n",
      "Epoch 124/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 125/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0784 - val_loss: 0.0788\n",
      "Epoch 126/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 127/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 128/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 129/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 130/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0784 - val_loss: 0.0788\n",
      "Epoch 131/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0788\n",
      "Epoch 132/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 133/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 134/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0783 - val_loss: 0.0788\n",
      "Epoch 135/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 136/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 137/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 138/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0783 - val_loss: 0.0788\n",
      "Epoch 139/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0783 - val_loss: 0.0788\n",
      "Epoch 140/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 141/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 142/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 143/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 144/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 145/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0784 - val_loss: 0.0787\n",
      "Epoch 146/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 147/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 148/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0783 - val_loss: 0.0788\n",
      "Epoch 149/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 150/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 151/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 152/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 153/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 154/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0783 - val_loss: 0.0787\n",
      "Epoch 155/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 7us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 156/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 157/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 158/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0787\n",
      "Epoch 159/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 160/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 161/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 162/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0786\n",
      "Epoch 163/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0787\n",
      "Epoch 164/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 165/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0782 - val_loss: 0.0786\n",
      "Epoch 166/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0786\n",
      "Epoch 167/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 168/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0786\n",
      "Epoch 169/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 170/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 171/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0786\n",
      "Epoch 172/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0782 - val_loss: 0.0788\n",
      "Epoch 173/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 174/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0783 - val_loss: 0.0786\n",
      "Epoch 175/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0782 - val_loss: 0.0786\n",
      "Epoch 176/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0786\n",
      "Epoch 177/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0786\n",
      "Epoch 178/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 179/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 180/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 181/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 182/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 183/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0786\n",
      "Epoch 184/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 185/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 186/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 187/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0787\n",
      "Epoch 188/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0787\n",
      "Epoch 189/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 190/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 191/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 192/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0782 - val_loss: 0.0786\n",
      "Epoch 193/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0787\n",
      "Epoch 194/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0782 - val_loss: 0.0787\n",
      "Epoch 195/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 196/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 197/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 198/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 199/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 200/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 201/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 202/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 203/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 204/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 205/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 206/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 207/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0785\n",
      "Epoch 208/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 209/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0780 - val_loss: 0.0787\n",
      "Epoch 210/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 211/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0785\n",
      "Epoch 212/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 213/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0787\n",
      "Epoch 214/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 215/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 216/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0787\n",
      "Epoch 217/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0785\n",
      "Epoch 218/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 219/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 220/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 221/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0785\n",
      "Epoch 222/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0781 - val_loss: 0.0786\n",
      "Epoch 223/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0785\n",
      "Epoch 224/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 225/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0785\n",
      "Epoch 226/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 227/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 228/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 229/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0779 - val_loss: 0.0785\n",
      "Epoch 230/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 231/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 232/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0787\n",
      "Epoch 233/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0787\n",
      "Epoch 234/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 6us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 235/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0785\n",
      "Epoch 236/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 237/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0787\n",
      "Epoch 238/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 239/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0779 - val_loss: 0.0785\n",
      "Epoch 240/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 241/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 242/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 243/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 244/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 245/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0785\n",
      "Epoch 246/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 247/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 248/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 249/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 250/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 251/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 252/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 253/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 254/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 255/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 256/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0788\n",
      "Epoch 257/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 258/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0779 - val_loss: 0.0786\n",
      "Epoch 259/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 260/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 261/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 262/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 263/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 264/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 265/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0787\n",
      "Epoch 266/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 267/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 268/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 269/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 270/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0786\n",
      "Epoch 271/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0786\n",
      "Epoch 272/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 273/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 274/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 275/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 276/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 277/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 278/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 279/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 7us/sample - loss: 0.0777 - val_loss: 0.0786\n",
      "Epoch 280/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0786\n",
      "Epoch 281/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 282/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 283/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 284/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 285/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 286/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 7us/sample - loss: 0.0777 - val_loss: 0.0786\n",
      "Epoch 287/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0778 - val_loss: 0.0785\n",
      "Epoch 288/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 289/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0786\n",
      "Epoch 290/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 291/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0776 - val_loss: 0.0785\n",
      "Epoch 292/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 293/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 294/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 295/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0776 - val_loss: 0.0785\n",
      "Epoch 296/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 297/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 298/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0786\n",
      "Epoch 299/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 300/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0776 - val_loss: 0.0785\n",
      "Epoch 301/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0776 - val_loss: 0.0785\n",
      "Epoch 302/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0776 - val_loss: 0.0785\n",
      "Epoch 303/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0776 - val_loss: 0.0785\n",
      "Epoch 304/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 6us/sample - loss: 0.0776 - val_loss: 0.0786\n",
      "Epoch 305/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0776 - val_loss: 0.0785\n",
      "Epoch 306/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.079 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - 1s 5us/sample - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 307/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0786\n",
      "Epoch 627/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0786\n",
      "Epoch 628/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0785\n",
      "Epoch 629/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 630/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 631/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 632/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 633/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 634/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0786\n",
      "Epoch 635/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 0s 5us/sample - loss: 0.0766 - val_loss: 0.0788\n",
      "Epoch 636/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0787\n",
      "Epoch 637/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0786\n",
      "Epoch 638/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0786\n",
      "Epoch 639/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0786\n",
      "Epoch 640/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0786\n",
      "Epoch 641/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0765 - val_loss: 0.0785\n",
      "Epoch 642/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 643/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0788\n",
      "Epoch 644/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 645/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0786\n",
      "Epoch 646/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 647/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 7us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 648/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 649/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 650/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 651/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 652/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 653/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 654/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 655/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0767 - val_loss: 0.0786\n",
      "Epoch 656/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 7us/sample - loss: 0.0765 - val_loss: 0.0788\n",
      "Epoch 657/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0767 - val_loss: 0.0787\n",
      "Epoch 658/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0765 - val_loss: 0.0786\n",
      "Epoch 659/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 660/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 661/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 662/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 663/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0765 - val_loss: 0.0786\n",
      "Epoch 664/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0786\n",
      "Epoch 665/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 666/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0787\n",
      "Epoch 667/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 668/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 669/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0788\n",
      "Epoch 670/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 0s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 671/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 672/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.078 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0786\n",
      "Epoch 673/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0765 - val_loss: 0.0788\n",
      "Epoch 674/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0787\n",
      "Epoch 675/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 676/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 677/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0788\n",
      "Epoch 678/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 679/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 680/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0764 - val_loss: 0.0787\n",
      "Epoch 681/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 682/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 683/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 684/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 685/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 0s 5us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 686/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 687/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0764 - val_loss: 0.0786\n",
      "Epoch 688/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0767 - val_loss: 0.0787\n",
      "Epoch 689/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 0s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 690/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0786\n",
      "Epoch 691/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0788\n",
      "Epoch 692/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 693/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0764 - val_loss: 0.0789\n",
      "Epoch 694/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 695/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 696/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 697/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 698/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0789\n",
      "Epoch 699/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0764 - val_loss: 0.0786\n",
      "Epoch 700/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0786\n",
      "Epoch 701/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 702/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0789\n",
      "Epoch 703/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 704/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0788\n",
      "Epoch 705/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 0s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 706/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0786\n",
      "Epoch 707/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 708/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 709/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 710/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 0s 5us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 711/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0764 - val_loss: 0.0789\n",
      "Epoch 712/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 0s 5us/sample - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 713/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 0s 5us/sample - loss: 0.0765 - val_loss: 0.0787\n",
      "Epoch 714/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0761 - val_loss: 0.0788\n",
      "Epoch 880/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0761 - val_loss: 0.0788\n",
      "Epoch 881/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.077 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0762 - val_loss: 0.0787\n",
      "Epoch 882/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0761 - val_loss: 0.0787\n",
      "Epoch 883/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0762 - val_loss: 0.0790\n",
      "Epoch 884/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0763 - val_loss: 0.0789\n",
      "Epoch 885/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0763 - val_loss: 0.0788\n",
      "Epoch 886/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0762 - val_loss: 0.0788\n",
      "Epoch 887/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0761 - val_loss: 0.0788\n",
      "Epoch 888/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.074 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0761 - val_loss: 0.0788\n",
      "Epoch 889/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0762 - val_loss: 0.0788\n",
      "Epoch 890/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 6us/sample - loss: 0.0761 - val_loss: 0.0788\n",
      "Epoch 891/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - ETA: 0s - loss: 0.075 - 1s 5us/sample - loss: 0.0760 - val_loss: 0.0788\n",
      "Epoch 892/5000\n",
      "105894/105894 [==============================] - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - ETA: 0s - loss: 0.076 - 1s 5us/sample - loss: 0.0761 - val_loss: 0.0788\n",
      "Epoch 893/5000\n",
      "\r"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Dense(100, activation='relu',\n",
    "                      input_shape=(len(feature_names),),\n",
    "                      kernel_initializer=initializers.he_normal(seed=0)))\n",
    "model.add(layers.Dense(100, activation='relu',\n",
    "                      kernel_initializer=initializers.he_normal(seed=0)))\n",
    "model.add(layers.Dropout(0.7))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=\"adam\",)\n",
    "\n",
    "print('start fitting')\n",
    "history = model.fit(dataset_train[feature_names], dataset_train['rank'],\n",
    "                    batch_size=10000, #1000\n",
    "                    epochs=5000, #225\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['val_loss'][1:])\n",
    "plt.plot(history.history['loss'][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "cf = lgb.LGBMRegressor(n_estimators=500)\n",
    "cf.fit(dataset_train[feature_names].astype(float), dataset_train['rank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cf2 = RandomForestRegressor(n_estimators=100)\n",
    "cf2.fit(dataset_train[feature_names].astype(float), dataset_train['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(zip(cf.feature_importances_, feature_names), \n",
    "                           columns=['Value','Feature']).sort_values('Value', ascending=False)\n",
    "feature_imp\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_drop = dataset.dropna(subset=feature_names+['return'])\n",
    "\n",
    "vals = model.predict(dataset_drop[feature_names].astype(float))\n",
    "dataset_drop['result1'] = pd.Series(vals.swapaxes(0,1)[0], dataset_drop.index)\n",
    "\n",
    "vals = cf.predict(dataset_drop[feature_names].astype(float))\n",
    "dataset_drop['result2'] = pd.Series(vals, dataset_drop.index)\n",
    "\n",
    "vals = cf2.predict(dataset_drop[feature_names].astype(float))\n",
    "dataset_drop['result3'] = pd.Series(vals, dataset_drop.index)\n",
    "\n",
    "dataset_drop = dataset_drop.reset_index().set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "dates = sorted(list(set(dataset_drop.index)))\n",
    "\n",
    "rs = []\n",
    "for d in dates:\n",
    "    \n",
    "    dataset_time = dataset_drop.loc[d]\n",
    "    \n",
    "    dataset_time = drop_extreme_case(dataset_time, \n",
    "        ['bias60', 'bias120', 'bias240', 'mom1', 'mom2', 'mom3', 'mom4', 'mom5', 'mom6','yoy','delta_yoy'], thresh=0.01)\n",
    "    \n",
    "    rank = dataset_time['result1'] + dataset_time['result2'] + dataset_time['result3'] \n",
    "    \n",
    "    condition = (rank >= rank.nlargest(20).iloc[-1]) \n",
    "    r = dataset_time['return'][condition].mean()\n",
    "\n",
    "    rs.append(r * (1-3/1000-1.425/1000*2*0.6))\n",
    "\n",
    "rs = pd.Series(rs, index=dates)['2018':].cumprod()\n",
    "\n",
    "s0050 = close['0050']['2018':]\n",
    "\n",
    "pd.DataFrame({'nn strategy return':rs.reindex(s0050.index, method='ffill'), '0050 return':s0050/s0050[0]}).plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs = [-1] ** (1/3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 當月持股狀況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.index.levels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest dataset\n",
    "last_date = \"2022-07-15\"#dataset.index.levels[1].max()\n",
    "is_last_date = dataset.index.get_level_values('date') == last_date\n",
    "last_dataset = dataset[is_last_date].copy()\n",
    "\n",
    "\n",
    "last_dataset = drop_extreme_case(last_dataset, \n",
    "    ['bias60', 'bias120', 'bias240', 'mom1', 'mom2', 'mom3', 'mom4', 'mom5', 'mom6','yoy','delta_yoy'], thresh=0.01)\n",
    "\n",
    "\n",
    "# remove NaN testcases\n",
    "last_dataset = last_dataset.dropna(subset=feature_names)\n",
    "\n",
    "# predict\n",
    "\n",
    "vals = model.predict(last_dataset[feature_names].astype(float))\n",
    "last_dataset['result1'] = pd.Series(vals.swapaxes(0,1)[0], last_dataset.index)\n",
    "\n",
    "vals = cf.predict(last_dataset[feature_names].astype(float))\n",
    "last_dataset['result2'] = pd.Series(vals, last_dataset.index)\n",
    "\n",
    "vals = cf2.predict(last_dataset[feature_names].astype(float))\n",
    "last_dataset['result3'] = pd.Series(vals, last_dataset.index)\n",
    "\n",
    "# calculate score\n",
    "\n",
    "rank = last_dataset['result1'] + last_dataset['result2'] + last_dataset['result3']\n",
    "condition = (rank >= rank.nlargest(20).iloc[-1]) \n",
    "\n",
    "# plot rank distribution\n",
    "rank.hist(bins=20)\n",
    "\n",
    "\n",
    "# show the best 20 stocks\n",
    "slist1 = rank[condition].reset_index()['stock_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 平均分配資產於股票之中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = data.get(\"收盤價\")\n",
    "\n",
    "money = 500000\n",
    "stock_prices = close[rank[condition].reset_index()['stock_id']].iloc[-1]\n",
    "\n",
    "\n",
    "print(\"股票平分張數:\")\n",
    "money / len(stock_prices) / stock_prices / 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finlab",
   "language": "python",
   "name": "finlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
